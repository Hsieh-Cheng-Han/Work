{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "課程3-1：CNN + YOLO物件偵測.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMO8GMrUBPzByasqd0VFYkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hsieh-Cheng-Han/Work/blob/master/%E8%AA%B2%E7%A8%8B3_1%EF%BC%9ACNN_%2B_YOLO%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NI_ImMAL1GL",
        "colab_type": "text"
      },
      "source": [
        "# **課程3-1：CNN + YOLO物件偵測**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0am_5KRlMAi8",
        "colab_type": "text"
      },
      "source": [
        "在上一次的深度學習練習中，我們看到如何用最簡易的全連接神經網路去辨識**MNIST**手寫數字。\n",
        "\n",
        "這次我們會進行複雜一點的辨識任務，並且採用**CNN**(卷積神經網路)的架構來達成。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq9-obwafx19",
        "colab_type": "text"
      },
      "source": [
        "## **Cifar-10資料集**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln8WcW3df6Vy",
        "colab_type": "text"
      },
      "source": [
        "**Cifar-10**包含6萬筆32*32的彩色圖片，類別一共有10個，詳細資料如下："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9baIsOjgzaO",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1PvHBHz6lq9tf8I_5mC-Rz-xaq04-RMul)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK2SFFgrg-ju",
        "colab_type": "text"
      },
      "source": [
        "**Cifar-10** 的所有圖片被分為 10 個類別 (以 0~9 數字作為 Label 之編碼) :\n",
        "0 : airplain (飛機)\n",
        "1 : automobile (汽車)\n",
        "2 : bird (鳥)\n",
        "3 : cat (貓)\n",
        "4 : deer (鹿)\n",
        "5 : dog (狗)\n",
        "6 : frog (青蛙)\n",
        "7 : horse (馬)\n",
        "8 : ship (船)\n",
        "9 : truck (卡車)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnaANaZuhW3P",
        "colab_type": "text"
      },
      "source": [
        "以下就讓我們建立**CNN**模型來進行辨識吧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Afb0GGL7qb",
        "colab_type": "code",
        "outputId": "a125d1e9-0e8a-4efb-b35c-e47defa05816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "# 載入cifar10資料集，並分成訓練用(train)和測試用(test)\n",
        "from keras.datasets import cifar10\n",
        "(x_train_image, y_train_label), (x_test_image, y_test_label) = cifar10.load_data() \n",
        "# 載入numpy模組\n",
        "import numpy as np   \n",
        "# 設定亂數seed，可以先不理它\n",
        "np.random.seed(10) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH-C7wEZj4Kg",
        "colab_type": "text"
      },
      "source": [
        "讓我們先了解一下資料長相："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_-1urfzjEkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('訓練集的圖片：', x_train_image.shape)\n",
        "print('測試集的圖片：', x_test_image.shape)\n",
        "print('訓練集的標籤：', y_train_label.shape)\n",
        "print('測試集的標籤：', y_test_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLftpFigj7wS",
        "colab_type": "text"
      },
      "source": [
        "(50000, 32, 32, 3)代表：**50000**張圖片，每張圖片長**32**，寬**32**，有**3**個channel。\n",
        "\n",
        "(50000, 1)代表：**50000**張圖片，每張圖片的標籤有**1**個數字。\n",
        "\n",
        "channel是電腦視覺中的重要術語，黑白圖片為1，彩色圖片因為是RGB三張圖片組合而成，所以channel數為3。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxW6H7C6j1uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 圖片的資料處理，所有數值除255\n",
        "x_train_image = x_train_image.astype('float32')/255.0\n",
        "x_test_image = x_test_image.astype('float32')/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO2mt4Kyl91-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 標籤的部分用上次提到的One Hot Encoding處理成[0,0,0,1,0..]形式\n",
        "from keras.utils import np_utils\n",
        "y_train_onehot = np_utils.to_categorical(y_train_label)\n",
        "y_test_onehot = np_utils.to_categorical(y_test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9-sfaXjmh54",
        "colab_type": "text"
      },
      "source": [
        "資料處理好後就讓我們來建立模型吧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l68NCeQqnR52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 載入需要的深度學習模組\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "\n",
        "# Sequential代表建立一個空模型，之後可以逐步疊加各種網路\n",
        "model = Sequential()\n",
        "\n",
        "# 建立第一層卷積層\n",
        "model.add(Conv2D(filters=32,     # 這一層有32個卷積\n",
        "                 kernel_size=(3,3),  # 每一個卷積大小為3*3小正方形\n",
        "                 padding='same',   # padding可以讓卷積處理完的新圖片不會變小 \n",
        "                 input_shape=(32,32,3), # 第一層需要告訴CNN輸入的圖片大小\n",
        "                 activation='relu')) # 卷積完要用relu這個激勵函數處理\n",
        "\n",
        "# 建立第一層池化層，這裡是用最大池化(MaxPooling)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # 池子大小為2*2小方格\n",
        "\n",
        "# 建立第二層卷積層，注意這裏的卷積數變成64，而且因為不是第一層，不需輸入input_size\n",
        "model.add(Conv2D(filters=64,\n",
        "                 kernel_size=(3,3),\n",
        "                 padding='same',\n",
        "                 activation='relu'))\n",
        "# 建立第二層池化層\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# 攤平\n",
        "model.add(Flatten())\n",
        "\n",
        "# 建立全連接層\n",
        "model.add(Dense(1024, activation='relu')) # 這一層的輸出為1024個單元\n",
        "\n",
        "# 最後一層，由於最後輸出是10個類別，所以輸出單元數為10，而且必須用softmax當作激勵函數\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKLkohSZqTlt",
        "colab_type": "text"
      },
      "source": [
        "模型建立完後，我們先了解一下他的長相吧。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udken-T8qW8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeRkkfoCqdSA",
        "colab_type": "text"
      },
      "source": [
        "可以看到總參數量為422萬左右，這個參數量尚可接受。\n",
        "\n",
        "之後就可以把資料餵進去模型進行訓練："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-UOpQWuqnDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練模型\n",
        "# categorical_crossentropy是分類問題常見的損失函數，數學式子可以自己上網看看\n",
        "# adam是一種參數學習的方法，不同的optimizer會讓機器有不同的學習方式\n",
        "# accuracy(準確度)是模型好壞的衡量標準\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# 餵資料進去模型\n",
        "model.fit(x = x_train_image, y = y_train_onehot, validation_split=0.2, epochs=10, batch_size=128,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdqkHsuptRV9",
        "colab_type": "text"
      },
      "source": [
        " Epoch數目代表跑過幾次訓練資料集，常常機器需要看訓練資料集好幾遍才能有良好的學習效果，我們這邊設定為10。\n",
        "\n",
        " 注意一下隨著Epoch數目增加，val_loss逐漸減少，這代表機器有在讓損失函數越來越少。而val_acc逐漸增加代表機器的衡量準確度越來越準。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW-inZaLt1Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 用測試資料集來做最後評估\n",
        "scores = model.evaluate(x_test_image, y_test_onehot) \n",
        "print(\"Accuracy = \", scores[1])\n",
        "\n",
        "# 前20張圖片預測結果和實際標籤比對\n",
        "prediction = model.predict_classes(x_test_image)\n",
        "print('預測結果：', prediction[:20])\n",
        "print('正確標籤：', y_test_label[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLGsXHxlwgWD",
        "colab_type": "text"
      },
      "source": [
        "測試集上預測結果為71.8%左右，還可接受。\n",
        "\n",
        "實務上會連接20多層的卷積和池化層，也會利用各種技巧和串接方式達到更好效果，有興趣的話可以來問我喔。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtKhUcxFLQuT",
        "colab_type": "text"
      },
      "source": [
        "## **YOLO**物件偵測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIxO83v55zwz",
        "colab_type": "text"
      },
      "source": [
        "程式碼來源：https://towardsdatascience.com/object-detection-using-yolov3-using-keras-80bf35e61ce1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r_Vl2g2LV-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 載入需要模組\n",
        "import os\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import struct\n",
        "import cv2\n",
        "from numpy import expand_dims\n",
        "import tensorflow as tf\n",
        "from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib.patches import Rectangle\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9vzW32WOgHQ",
        "colab_type": "text"
      },
      "source": [
        "之後，我們會讀取已經訓練好的**YOLO**模型參數(我們就不需要花大筆時間去訓練了！！)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqZZZ6fLNIHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 以下程式碼執行完後會要你去指定連結獲取驗證碼，照著做再貼上即可\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '1eCnxHgBeeKwng1pJlLJnwJMAYy40SXyS'  \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('yolov3.weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Ur5hpvnMuZ",
        "colab_type": "text"
      },
      "source": [
        "之後的code就一路執行下去即可(有點長)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLaNVbHzfTnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,    = struct.unpack('i', w_f.read(4))\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "            \n",
        "            binary = w_f.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "        \n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance            \n",
        "\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    \n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))\n",
        "\n",
        "    def reset(self):\n",
        "        self.offset = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxstaYVjf7vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    \n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        \n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'], \n",
        "                   conv['kernel'], \n",
        "                   strides=conv['stride'], \n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']), \n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRKIbWswQJYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the YOLO model\n",
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "# Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "# Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "# Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "# Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "# Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "        \n",
        "    skip_36 = x\n",
        "        \n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "# Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "        \n",
        "    skip_61 = x\n",
        "        \n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "# Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "        \n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "# Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "# Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "# Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "# Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "# Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "# Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81vZqunbQhmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_h, net_w = 416, 416\n",
        "obj_thresh, nms_thresh = 0.5, 0.45\n",
        "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "# make the yolov3 model to predict 80 classes on COCO\n",
        "\n",
        "yolov3 = make_yolov3_model()\n",
        "\n",
        "# load the weights trained on COCO into the model\n",
        "weight_reader = WeightReader('yolov3.weights')\n",
        "weight_reader.load_weights(yolov3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQkkyRHCggYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import expand_dims\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo6cAN76hwIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3 \n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "def do_nms(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "        \n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymLbEiirh-e-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#decode_netout() that will take each one of the NumPy arrays, one at a time, \n",
        "#and decode the candidate bounding boxes and class predictions\n",
        "def decode_netout(netout, anchors, obj_thresh,  net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        \n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            #objectness = netout[..., :4]\n",
        "            \n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "            \n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n",
        "            \n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            \n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFLx1DzriFI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bounding boxes will be stretched back into the shape of the original image\n",
        "#will allow plotting the original image and draw the bounding boxes, hopefully detecting real objects.\n",
        "# correct the sizes of the bounding boxes for the shape of the image\n",
        "#correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "        \n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        \n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBUBShQSiHa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    # load the image\n",
        "    data = plt.imread(filename)\n",
        "    # plot the image\n",
        "    plt.imshow(data)\n",
        "    # get the context for drawing boxes\n",
        "    ax = plt.gca()\n",
        "    # plot each box\n",
        "    for i in range(len(v_boxes)):\n",
        "        box = v_boxes[i]\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        # calculate width and height of the box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        # create the shape\n",
        "        rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "        # draw the box\n",
        "        ax.add_patch(rect)\n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        plt.text(x1, y1, label, color='red')\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdyKetT3iKXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "        # enumerate all possible labels\n",
        "        for i in range(len(labels)):\n",
        "            # check if the threshold for this label is high enough\n",
        "            if box.classes[i] > thresh:\n",
        "                v_boxes.append(box)\n",
        "                v_labels.append(labels[i])\n",
        "                v_scores.append(box.classes[i]*100)\n",
        "                # don't break, many labels may trigger for one box\n",
        "    return v_boxes, v_labels, v_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mWi4iXbl9qs",
        "colab_type": "text"
      },
      "source": [
        "這邊用我們的街景圖片做示範"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiT2okiTmDCk",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1f6BCmPEz8hxEUKrqerJufBWUDf8DfJGO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd_XizKUlmb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '1f6BCmPEz8hxEUKrqerJufBWUDf8DfJGO'  \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('my_photo.jpg')\n",
        "\n",
        "# define the expected input shape for the model\n",
        "input_w, input_h = 416, 416\n",
        "# define our new photo\n",
        "photo_filename = 'my_photo.jpg'\n",
        "# load and prepare image\n",
        "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6isdcAsUijNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make prediction\n",
        "yolos = yolov3.predict(image)\n",
        "# summarize the shape of the list of arrays\n",
        "print([a.shape for a in yolos])\n",
        "\n",
        "# define the anchors\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.6\n",
        "boxes = list()\n",
        "\n",
        "for i in range(len(yolos)):\n",
        "        # decode the output of the network\n",
        "    boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh,  net_h, net_w)\n",
        "\n",
        "    # correct the sizes of the bounding boxes\n",
        "correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\n",
        "# suppress non-maximal boxes\n",
        "do_nms(boxes, nms_thresh)\n",
        "\n",
        "# get the details of the detected objects\n",
        "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "# summarize what we found\n",
        "for i in range(len(v_boxes)):\n",
        "    print(v_labels[i], v_scores[i])\n",
        "# draw what we found\n",
        "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKjjqOjqk9Dk",
        "colab_type": "text"
      },
      "source": [
        "以上就是利用**YOLO**完成物件偵測的結果，大家試著用自己的圖片玩看看吧。"
      ]
    }
  ]
}